{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72219142",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\Projects\\\\ML_Models\\\\BrainTome\\\\results\\\\models\\\\best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m model = UNet3D(in_channels=\u001b[32m4\u001b[39m, out_channels=\u001b[32m1\u001b[39m).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     31\u001b[39m model.eval()\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# üì° Register a hook on bottleneck\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Projects\\ML_Models\\BrainTome\\venv\\Lib\\site-packages\\torch\\serialization.py:1479\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1477\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1480\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1481\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1482\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1483\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1484\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Projects\\ML_Models\\BrainTome\\venv\\Lib\\site-packages\\torch\\serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Projects\\ML_Models\\BrainTome\\venv\\Lib\\site-packages\\torch\\serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'F:\\\\Projects\\\\ML_Models\\\\BrainTome\\\\results\\\\models\\\\best_model.pth'"
     ]
    }
   ],
   "source": [
    "# üß† U-Net Bottleneck Feature Map Visualization (Animated GIF Style)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# üîß Add src to Python path\n",
    "project_root = r\"F:\\Projects\\ML_Models\\BrainTome\"\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# üìÇ Paths - Customize for your system\n",
    "MODEL_PATH = r\"F:\\Projects\\ML_Models\\BrainTome\\results\\models\\best_model.pth\"\n",
    "DATA_DIR = r\"F:\\Projects\\ML_Models\\BrainTome\\patch_dataset\\BraTS-GLI-00025-000\"\n",
    "GIF_OUTPUT_PATH = r\"F:\\Projects\\ML_Models\\BrainTome\\results\\feature_maps\\bottleneck_feature_maps.gif\"\n",
    "\n",
    "# ‚úÖ Create result folder if it doesn't exist\n",
    "os.makedirs(os.path.dirname(GIF_OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "# ‚úÖ Import model\n",
    "from src.model import UNet3D\n",
    "\n",
    "# üöÄ Load trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet3D(in_channels=4, out_channels=1).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# üì° Register a hook on bottleneck\n",
    "feature_maps = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    feature_maps.append(output.detach().cpu().numpy())\n",
    "\n",
    "hook = model.bottleneck.register_forward_hook(hook_fn)\n",
    "\n",
    "# üì¶ Load a sample patch\n",
    "X_path = os.path.join(DATA_DIR, \"X_0.npy\")\n",
    "X_patch = np.load(X_path)  # Shape: (4, 64, 64, 64)\n",
    "X_tensor = torch.tensor(X_patch).unsqueeze(0).to(device).float()\n",
    "\n",
    "# üîç Forward pass to extract feature maps\n",
    "with torch.no_grad():\n",
    "    _ = model(X_tensor)\n",
    "\n",
    "# üéØ Process the bottleneck feature maps\n",
    "feat = feature_maps[0][0]  # shape: (num_channels, D, H, W)\n",
    "print(f\"[INFO] Feature map shape: {feat.shape}\")\n",
    "\n",
    "# üéûÔ∏è Convert channels to 2D slices and make frames\n",
    "frames = []\n",
    "for i in range(feat.shape[0]):\n",
    "    slice_2d = feat[i, :, :, feat.shape[3] // 2]  # Mid-axial slice\n",
    "    normed = (slice_2d - np.min(slice_2d)) / (np.ptp(slice_2d) + 1e-8)\n",
    "    img = (normed * 255).astype(np.uint8)\n",
    "    frames.append(img)\n",
    "\n",
    "# üé¨ Save animated GIF\n",
    "imageio.mimsave(GIF_OUTPUT_PATH, frames, duration=0.12)\n",
    "print(f\"‚úÖ GIF saved to: {GIF_OUTPUT_PATH}\")\n",
    "\n",
    "# üñºÔ∏è Display the result\n",
    "display(Image(GIF_OUTPUT_PATH))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
